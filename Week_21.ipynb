{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2a2a0taA3Pm",
        "outputId": "61dbf1e4-f10c-4418-8448-e88ad720379a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 108s 167ms/step - loss: 0.4520 - acc: 0.7826 - val_loss: 0.4738 - val_acc: 0.8216\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 103s 164ms/step - loss: 0.2810 - acc: 0.8881 - val_loss: 0.2972 - val_acc: 0.8830\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 101s 161ms/step - loss: 0.2325 - acc: 0.9110 - val_loss: 0.3394 - val_acc: 0.8664\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 98s 157ms/step - loss: 0.2039 - acc: 0.9237 - val_loss: 0.3354 - val_acc: 0.8808\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 102s 163ms/step - loss: 0.1844 - acc: 0.9327 - val_loss: 0.2929 - val_acc: 0.8854\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 0.3042 - acc: 0.8779\n",
            "Test loss: 0.3041697144508362, Test accuracy: 0.8778799772262573\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# Load the IMDB dataset\n",
        "max_features = 10000  # Only consider the top 10,000 words in the dataset\n",
        "max_len = 500  # Cut reviews after 500 words\n",
        "batch_size = 32\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "results = model.evaluate(x_test, y_test)\n",
        "print(f'Test loss: {results[0]}, Test accuracy: {results[1]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Example new sentence\n",
        "new_sentence = \"This movie was really good!\"\n",
        "\n",
        "# Tokenize and pad the new sentence\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts([new_sentence])\n",
        "new_sentence_sequence = tokenizer.texts_to_sequences([new_sentence])\n",
        "new_sentence_padded = pad_sequences(new_sentence_sequence, maxlen=max_len)\n",
        "\n",
        "# Make predictions using the trained model\n",
        "prediction = model.predict(new_sentence_padded)\n",
        "\n",
        "# Interpret the prediction\n",
        "if prediction[0, 0] >= 0.5:\n",
        "    sentiment = 'positive'\n",
        "else:\n",
        "    sentiment = 'negative'\n",
        "\n",
        "print(f'The predicted sentiment for the new sentence is {sentiment} (Probability: {prediction[0, 0]})')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNHKLqjuA53F",
        "outputId": "2b3d377d-6952-47ba-ce63-8fc35e78966e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 443ms/step\n",
            "The predicted sentiment for the new sentence is positive (Probability: 0.5372642874717712)\n"
          ]
        }
      ]
    }
  ]
}